<head>
<meta name="description" content="SuperSCS: Fast and Accurate Conic Programming"/>
<meta name="keywords" content="Optimization, Conic Programming, Conic Problems, Cone Programs"/>
<meta name="distribution" content="Global"/>
<meta name="author" content="Pantelis Sopasakis"/>
<meta name="robots" content="index,follow"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<meta charset="UTF-8"/>
<meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.6"/>
<title>SuperSCS: SuperSCS: Fast &amp; Accurate conic programming</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script src="https://cdn.rawgit.com/mathjax/MathJax/2.7.1/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="dox_extra.css" rel="stylesheet" type="text/css"/>
<!-- Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-117903175-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-117903175-1');
</script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="logo.png"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">SuperSCS
   &#160;<span id="projectnumber">1.3.2</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.6 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Home</span></a></li>
      <li class="current"><a href="pages.html"><span>All&#160;pages</span></a></li>
      <li><a href="annotated.html"><span>Structures</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Data Structures</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Macros</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">The SuperSCS Algorithm </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="superscs-problem-statement"></a>
Conic Optimization and HSDE</h1>
<p>SCS and SuperSCS solve the following problem</p>
<p class="formulaDsp">
\begin{eqnarray*} &amp;&amp;\mathrm{Minimize}\ \langle c, x \rangle\\ &amp;&amp;Ax + s = b\\ &amp;&amp;s\in\mathcal{K}, \end{eqnarray*}
</p>
<p>where \(x\in\mathbb{R}^n\), \(s\in\mathbb{R}^m\) are the primal variables and \(\mathcal{K}\subseteq\mathbb{R}^m\) is a nonempty, closed, convex cone.</p>
<p>The matrix \(A\in\mathbb{R}^{m\times n}\) and the vector \(b\in\mathbb{R}^m\) are the problem data.</p>
<p>The algorithm makes use of the <a href="https://mathematix.wordpress.com/2017/06/05/cone-programs-and-self-dual-embeddings/">homogeneous self-dual embedding</a> (HSDE) which is the problem of finding a \(u=(x,y,\tau)\in\mathbb{R}^{n+m+1}\) so that</p>
<p class="formulaDsp">
\begin{eqnarray*} &amp;&amp;u\in\mathcal{C}\\ &amp;&amp;Qu\in\mathcal{C}^*\\ &amp;&amp;\langle u, Qu \rangle = 0, \end{eqnarray*}
</p>
<p>where</p>
<p class="formulaDsp">
\begin{eqnarray*} Q = \begin{bmatrix} 0 &amp; A^* &amp; c\\ -A &amp; 0 &amp; b\\ -c^* &amp; -b^* &amp; 0 \end{bmatrix} \end{eqnarray*}
</p>
<p>and \(\mathcal{C} = \mathbb{R}^n\times \mathcal{K}^* \times \mathbb{R}_+\) is a cone.</p>
<p>Equivalently, the HSDE can be written as a variational inequality:</p>
<p class="formulaDsp">
\begin{eqnarray*} 0 \in Qu + N_{\mathcal{C}}(u), \end{eqnarray*}
</p>
<p>where \(N_{\mathcal{C}}\) is the normal cone of \(\mathcal{C}\).</p>
<h1><a class="anchor" id="superscs-algorithmic-solution"></a>
Algorithmic Solution</h1>
<h2><a class="anchor" id="superscs-sec-douglas-rachford"></a>
Douglas-Rachford Splitting for HSDE</h2>
<p>The Douglas-Rachford splitting can be applied to the above variational problem.</p>
<p>Operator \(T\) is a (firmly) nonexpansive operator on which we may apply the <b>SuperMann</b> algorithmic scheme.</p>
<p>Since \(Q\) is a skew-symmetric linear operator, it is maximally monotone.</p>
<p>Since \(N_{\mathcal{C}}\) is the subdifferential of the proper convex function \(\delta_{\mathcal{C}}\), it is maximally monotone.</p>
<p>Additionally, because of Cor. 24.4(i) in <a class="el" href="page_superscs.html#page_superscs_refs">[BauCom]</a>, \(Q+N_{\mathcal{C}}\) is maximally monotone.</p>
<p>Therefore, we may apply the Douglas-Rachford splitting on this monotone inclusion.</p>
<p>The SCS algorithm <a class="el" href="page_superscs.html#page_superscs_refs">[ODon16]</a> is precisely the application of the Douglas-Rachford splitting (DRS) to \(N_{\mathcal{C}}{}+{}Q\); this leads to the following iterations; see Sec. 7.3 in <a class="el" href="page_superscs.html#page_superscs_refs">[RyuBoy16]</a></p>
<p class="formulaDsp">
\begin{eqnarray*} \tilde{u}^{\nu} {}={}&amp; (I+Q)^{-1}(u^{\nu}) \\ \bar{u}^{\nu} {}={}&amp; \Pi_{\mathcal{C}}(2\tilde{u}^{\nu} - u^{\nu}) \\ u^{\nu+1} {}={}&amp; u^{\nu} {}+{} \bar{u}^{\nu} {}-{} \tilde{u}^{\nu} \end{eqnarray*}
</p>
<p>Here, on the other hand, we consider the opposite DRS splitting, \(Q+N_{\mathcal{C}}\), which leads to the following DRS iterations </p>
<p class="formulaDsp">
\begin{eqnarray*} \tilde{u}^{\nu} {}={}&amp; \Pi_{\mathcal{C}}(u^{\nu}) \\ \bar{u}^{\nu} {}={}&amp; (I+Q)^{-1}(2\tilde{u}^{\nu} - u^{\nu}) \\ u^{\nu+1} {}={}&amp; u^{\nu} {}+{} \bar{u}^{\nu} {}-{} \tilde{u}^{\nu} \end{eqnarray*}
</p>
<p> For any initial guess \(u^0\), the iterates \(u^\nu\) converge to a point \(u^\star\) which satisfies the above monotone inclusion; see Thm. 25.6(i), (iv) in <a class="el" href="page_superscs.html#page_superscs_refs">[BauCom11]</a>.</p>
<p>The linear system above can be either solved "directly" using a sparse LDL factorization or "indirectly" by means of the conjugate gradient method <a class="el" href="page_superscs.html#page_superscs_refs">[ODon16]</a>.</p>
<p>The projection on \(\mathcal{C}\) essentially requires that we be able to project on the dual cone, \(\mathcal{K}^*\)</p>
<p>The iterative method can be concisely written as </p>
<p class="formulaDsp">
\begin{eqnarray*} u^{\nu+1} = Tu^\nu, \end{eqnarray*}
</p>
<p> where \(T:\mathbb{R}^{N}\to\mathbb{R}^{N}\) is a (firmly) nonexpansive operator <a class="el" href="page_superscs.html#page_superscs_refs">[RyuBoy16]</a>. As such it fits the Krasnosel'skii-Mann framework, because of Sec. 5.2 in <a class="el" href="page_superscs.html#page_superscs_refs">[BauCom11]</a>, leading to the relaxed iterations</p>
<p class="formulaDsp">
\begin{eqnarray*} u^{\nu+1} {}={} (1-\lambda)u^\nu + \lambda Tu^{\nu}, \end{eqnarray*}
</p>
<p>with \(\lambda \in (0,2)\) since \(T\) is firmly nonexpansive and, as a result, it fits the SuperMann framework <a class="el" href="page_superscs.html#page_superscs_refs">[ThePat16]</a>.</p>
<h2><a class="anchor" id="superscs-sec-supermann-scheme"></a>
SuperMann</h2>
<p>SuperMann <a class="el" href="page_superscs.html#page_superscs_refs">[ThePat16]</a> reduces the problem of finding a fixed-point \(x^\star{}\in{}\operatorname{fix} T\) to that of finding a zero of the residual operator </p>
<p class="formulaDsp">
\begin{eqnarray*} R = I-T. \end{eqnarray*}
</p>
<p>SuperMann, instead of applying Krasnosel'skii-Mann-type updates as discussed above, takes extragradient-type updates of the general form </p>
<p class="formulaDsp">
\begin{eqnarray*} w^{\nu} {}={}&amp; u^{\nu} {}+{} \tau_\nu d^\nu, \\ u^{\nu+1} {}={}&amp; u^\nu - \zeta_{\nu} Rw^\nu, \end{eqnarray*}
</p>
<p> where \( d^{\nu} \) are fast, e.g., quasi-Newtonian, directions and scalar parameters \(\tau_{\nu}\) and \(\zeta_{\nu}\) are appropriately chosen so as to guarantee global convergence.</p>
<p>At each step either trigger fast convergence (K1 steps) or ensure global convergence (K2 steps) as shown below.</p>
<p>Alongside, a sufficient decrease of the norm of the residual, \(\|Ru^{\nu}\|\), may trigger a "blind update" of the form \( u^{\nu+1} {}={} u^{\nu} {}+{} d^{\nu}. \)</p>
<p><b>SuperSCS Algorithm</b></p>
<ul>
<li>Input: \(c_0, c_1, q\in [0,1)\), \(\sigma\in (0,1)\), \(u^0\in\mathbb{R}^N\), \(\lambda\in(0,2)\) and \(\epsilon&gt;0\)</li>
<li>\(\eta_0{}\gets{}\|Ru^0\|\), \(r_{\text{safe}}\gets \eta_0\)</li>
<li><b>For</b> \(\nu=0,1,\ldots\):<ul>
<li>Check <a class="el" href="page_termination.html">termination criteria</a> with tolerance \(\epsilon\)</li>
<li>Choose <a class="el" href="page_directions.html">direction</a> \(d^{\nu}\), let \(\tau_{\nu}{}\gets{}1\)</li>
<li><b>If</b> \( \|Ru^\nu\| {}\leq{} c_0 \eta_\nu \) <b>then</b> (K0, blind update)<ul>
<li>\( u^{\nu+1} {}\gets{} w^\nu \)</li>
<li>\( \eta_{\nu+1} {}\gets{} \|Ru^{\nu}\| \)</li>
</ul>
</li>
<li><b>else</b><ul>
<li>\( \eta_{\nu+1} {}\gets{} \eta_{\nu} \)</li>
<li><b>Loop</b> (<em>linesearch</em>):<ul>
<li>\( w^\nu {}\gets{} u^\nu {}+{} \tau_\nu d^\nu \) and \( \rho_{\nu} {}\gets{} \langle Rw^\nu, u^\nu {-} Tw^\nu\rangle \)</li>
<li><b>If</b> \( \|Ru^\nu\| {}\leq{} r_{\text{safe}} \) and \( \|Rw^\nu\| {}\leq{} c_1 \|Ru^\nu\| \) <b>then</b> K1 steps)<ul>
<li>\( u^{\nu+1} {}\gets{} w^\nu \),</li>
<li>\( r_{\text{safe}} {}\gets{} \|Rw^\nu\| + q^\nu \eta_0 \)</li>
<li>exit <em>linesearch</em></li>
</ul>
</li>
<li><b>Else If</b> \( \rho_{\nu} {}\geq{} \sigma \|Ru^\nu\| \|Rw^\nu\| \) <b>then</b> (K2 steps)<ul>
<li>\( u^{\nu+1} {}\gets{} u^\nu {}-{} \lambda\tfrac{\rho_\nu}{\|Rw^\nu\|^2}Rw^\nu \)</li>
<li>exit <em>linesearch</em></li>
</ul>
</li>
<li><b>Else</b><ul>
<li>\(\tau_{\nu}{}\gets{}{\tau_{\nu}}/{2}\)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>By exploiting the structure of \(T\) and, in particular, the fact that \((I+Q)^{-1}\) is a linear operator, we may avoid applying \(T\) at every iteration of the line search loop.</p>
<p>Instead, at every line search iteration we only need to apply \(\Pi_{\mathcal{C}}\) once.</p>
<p>SuperSCS does not need to solve a linear system within the line search loop.</p>
<p>Overall, save the computation of the residuals, at every iteration of SuperSCS we need to solve the linear system twice and invoke \(\Pi_{\mathcal{C}}\) only \(1+l_\nu\) times, where \(l_{\nu}\) is the number of line search iterations.</p>
<h1><a class="anchor" id="page_superscs_refs"></a>
References</h1>
<ul>
<li>[BauCom11] H.H. Bauschke and P.L. Combettes. <a href="http://www4.ncsu.edu/~pcombet/livre1.pdf">Convex analysis and monotone operator theory in Hilbert spaces</a>. Springer, 2011.</li>
<li>[ODon+16] B. Oâ€™Donoghue, E. Chu, N. Parikh, and S. Boyd. <a href="https://stanford.edu/~boyd/papers/pdf/scs_long.pdf">Conic optimization via operator splitting and homogeneous self-dual embedding</a>. JOTA 169(3):1042-1068, Jun 2016.</li>
<li>[RyuBoy16] E.K. Ryu and S. Boyd. <a href="http://stanford.edu/~boyd/papers/pdf/monotone_primer.pdf">A primer on monotone operator methods: a survey</a>. Appl. Comput. Math., 15(1):3-43, 2016.</li>
<li>[ThePat16] A. Themelis and P. Patrinos. <a href="https://arxiv.org/pdf/1609.06955.pdf">Supermann: a superlinearly convergent algorithm for finding fixed points of nonexpansive operators</a>. ArXiv 1609.06955, 2016. </li>
</ul>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Tue Aug 28 2018 15:45:56 for SuperSCS by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.6
</small></address>
</body>
</html>
